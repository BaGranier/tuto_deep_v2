{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TE2ItlsI956"
   },
   "source": [
    "# Séance 1 :  Deep Learning - Introduction à Pytorch \n",
    "\n",
    "Les notebooks sont très largement inspirés des cours de **N. Baskiotis et B. Piwowarski**. Ils peuvent être complétés efficacement par les tutoriels *officiels* présents sur le site de pytorch:\n",
    "https://pytorch.org/tutorials/\n",
    "\n",
    "Au niveau de la configuration, toutes les installations doivent fonctionner sur Linux et Mac. Pour windows, ça peut marcher avec Anaconda à jour... Mais il est difficile de récupérer les problèmes.\n",
    "\n",
    "* Aide à la configuration des machines: [lien](https://dac.lip6.fr/master/environnement-deep/)\n",
    "* Alternative 1 à Windows: installer Ubuntu sous Windows:  [Ubuntu WSL](https://ubuntu.com/wsl)\n",
    "* Alternative 2: travailler sur Google Colab (il faut un compte gmail + prendre le temps de comprendre comment accéder à des fichers) [Colab](https://colab.research.google.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3Y9YOOHHhJKY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La version de torch est :  2.2.2+cpu\n",
      "Le calcul GPU est disponible ?  False\n",
      "Le calcul GPU est disponible (apple) ?  False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"La version de torch est : \",torch.__version__)\n",
    "print(\"Le calcul GPU est disponible ? \", torch.cuda.is_available())\n",
    "\n",
    "# pour les possesseurs de mac M1 avec la dernière version de pytorch:\n",
    "print(\"Le calcul GPU est disponible (apple) ? \", torch.backends.mps.is_available())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'exemples :  20640 Dimension :  8\n",
      "Nom des attributs :  MedInc, HouseAge, AveRooms, AveBedrms, Population, AveOccup, Latitude, Longitude\n",
      "tensor([[ 8.3252e+00,  4.1000e+01,  6.9841e+00,  1.0238e+00,  3.2200e+02,\n",
      "          2.5556e+00,  3.7880e+01, -1.2223e+02],\n",
      "        [ 8.3014e+00,  2.1000e+01,  6.2381e+00,  9.7188e-01,  2.4010e+03,\n",
      "          2.1098e+00,  3.7860e+01, -1.2222e+02],\n",
      "        [ 7.2574e+00,  5.2000e+01,  8.2881e+00,  1.0734e+00,  4.9600e+02,\n",
      "          2.8023e+00,  3.7850e+01, -1.2224e+02],\n",
      "        [ 5.6431e+00,  5.2000e+01,  5.8174e+00,  1.0731e+00,  5.5800e+02,\n",
      "          2.5479e+00,  3.7850e+01, -1.2225e+02],\n",
      "        [ 3.8462e+00,  5.2000e+01,  6.2819e+00,  1.0811e+00,  5.6500e+02,\n",
      "          2.1815e+00,  3.7850e+01, -1.2225e+02]])\n"
     ]
    }
   ],
   "source": [
    "## Chargement des données housing (depuis sklearn) et transformation en tensor.\n",
    "# from sklearn.datasets import load_housing # => removed\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing(data_home=\"./data/\") ## chargement des données\n",
    "\n",
    "housing_x = torch.tensor(housing['data'],dtype=torch.float) # penser à typer les données pour éliminer les incertitudes\n",
    "housing_y = torch.tensor(housing['target'],dtype=torch.float)\n",
    "\n",
    "print(\"Nombre d'exemples : \",housing_x.size(0), \"Dimension : \",housing_x.size(1))\n",
    "print(\"Nom des attributs : \", \", \".join(housing['feature_names']))\n",
    "\n",
    "print(housing_x[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1rxv3ychdhD"
   },
   "source": [
    "## A. Architecture modulaires & réseaux de neurones\n",
    "Dans le framework pytorch (et dans la plupart des frameworks analogues), le module est la brique de base qui permet de construire un réseau de neurones.  Il permet de représenter en particulier :\n",
    "* une couche du réseau (linéaire : **torch.nn.Linear**, convolution : **torch.nn.convXd**, ...)\n",
    "* une fonction d'activation (tanh : **torch.nn.Tanh**, sigmoïde : **torch.nn.Sigmoid** , ReLu : **torch.nn.ReLu**, ...)\n",
    "* une fonction de coût (MSE : **torch.nn.MSELoss**, L1 :  **torch.nn.L1Loss**, CrossEntropy binaire: **torch.BCE**, CrossEntropy : **torch.nn.CrossEntropyLoss**, ...)\n",
    "* un ensemble de modules : en termes informatique, un module est un conteneur abstrait qui peut contenir d'autres conteneurs) : plusieurs modules peuvent être mis ensemble afin de former un nouveau module plus complexe.\n",
    "\n",
    "\n",
    "Le fonctionnement est très proche des fonctions que nous avons vu ci-dessus (un module encapsule en fait une fonction de **torch.nn.Function**), mais de manière à gérer automatiquement les paramètres à apprendre. Un module est ainsi muni :\n",
    "* d'une méthode **forward** qui permet de calculer la sortie du module à partir des entrées\n",
    "* d'une méthode **backward** qui permet d'effectuer la rétro-propagation (localement).\n",
    "* tous les paramètres sont automatiquement ajoutés dans une liste interne, accessible par la fonction **.parameters()** du module.\n",
    "\n",
    "Ci-dessous un exemple de régression linéaire en utilisant les modules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "spguRLUjD60C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sortie du réseau tensor([[ -98.5951],\n",
      "        [-780.6885],\n",
      "        [-153.2320],\n",
      "        [-174.1403],\n",
      "        [-176.2784],\n",
      "        [-127.0876],\n",
      "        [-349.2974],\n",
      "        [-369.8991],\n",
      "        [-387.7155],\n",
      "        [-498.4619]], grad_fn=<SliceBackward0>)\n",
      "Paramètres et noms des paramètres [(Parameter containing:\n",
      "tensor([[-0.0004,  0.1661,  0.2768, -0.1704, -0.3264, -0.0516,  0.2905,  0.1067]],\n",
      "       requires_grad=True), ('weight', Parameter containing:\n",
      "tensor([[-0.0004,  0.1661,  0.2768, -0.1704, -0.3264, -0.0516,  0.2905,  0.1067]],\n",
      "       requires_grad=True))), (Parameter containing:\n",
      "tensor([0.1128], requires_grad=True), ('bias', Parameter containing:\n",
      "tensor([0.1128], requires_grad=True)))]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=10\n",
    "EPS = 1e-7\n",
    "\n",
    "Xdim = housing_x.size(1)\n",
    "## Création d'une couche linéaire de dimension Xdim->1\n",
    "net = torch.nn.Linear(Xdim, 1) \n",
    "\n",
    "## Passe forward du module :  équivalent à net.forward(x)[:10]\n",
    "print(\"Sortie du réseau\", net(housing_x)[:10])\n",
    "## affiche la liste des paramètres du modèle\n",
    "print(\"Paramètres et noms des paramètres\", list(zip(list(net.parameters()), list(net.named_parameters()))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\torch2025\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration : 0, loss : 108443.0\n",
      "iteration : 1, loss : 12514.498046875\n",
      "iteration : 2, loss : 1739.9339599609375\n",
      "iteration : 3, loss : 529.0283813476562\n",
      "iteration : 4, loss : 392.2215576171875\n",
      "iteration : 5, loss : 376.0491638183594\n",
      "iteration : 6, loss : 373.42730712890625\n",
      "iteration : 7, loss : 372.3294372558594\n",
      "iteration : 8, loss : 371.40478515625\n",
      "iteration : 9, loss : 370.501708984375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Création d'une fonction de loss aux moindres carrés\n",
    "mseloss = torch.nn.MSELoss()\n",
    "## on créé un optimiseur pour le réseau (paramètres w et b), avec un pas de gradient lr\n",
    "optim = torch.optim.SGD(params=net.parameters(),lr=EPS) \n",
    "# Juste pour info, ce n'est pas utile, les paramètres sont déjà initialisés.\n",
    "net.reset_parameters()\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    loss = mseloss(net(housing_x).view(-1,1),housing_y.view(-1,1))\n",
    "    print(f\"iteration : {i}, loss : {loss}\")\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxdRGqZtSlVt"
   },
   "source": [
    "## A.1. Création d'un réseau de neurones\n",
    "\n",
    "Avec ces briques élémentaires, il est très facile de définir un réseau de neurones standard :\n",
    "* soit en utilisant le conteneur **torch.nn.Sequential** qui permet d'enchaîner séquentiellement plusieurs modules\n",
    "* soit en définissant à la main un nouveau module.\n",
    "\n",
    "Ci-dessous un exemple  pour créer un réseau à deux couches linéaires avec une fonction d'activation tanh des deux manières différentes. Vous remarquez qu'il n'y a pas besoin de définir la méthode **backward**, celle-ci est héritée du conteneur abstrait et ne fait qu'appeler séquentiellement en ordre inverse les méthodes **backward** des différents modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7c6I-PZRD-aN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration : 0, loss : 8.610703468322754\n",
      "iteration : 1, loss : 6.925062656402588\n",
      "iteration : 2, loss : 4.949126243591309\n",
      "iteration : 3, loss : 3.7194271087646484\n",
      "iteration : 4, loss : 3.1813366413116455\n",
      "iteration : 5, loss : 2.764545440673828\n",
      "iteration : 6, loss : 2.441706418991089\n",
      "iteration : 7, loss : 2.1916415691375732\n",
      "iteration : 8, loss : 1.9979454278945923\n",
      "iteration : 9, loss : 1.847912311553955\n",
      "iteration : 10, loss : 1.731699824333191\n",
      "iteration : 11, loss : 1.6416839361190796\n",
      "iteration : 12, loss : 1.571959376335144\n",
      "iteration : 13, loss : 1.5179523229599\n",
      "iteration : 14, loss : 1.476119875907898\n",
      "iteration : 15, loss : 1.4437174797058105\n",
      "iteration : 16, loss : 1.4186187982559204\n",
      "iteration : 17, loss : 1.399178147315979\n",
      "iteration : 18, loss : 1.3841197490692139\n",
      "iteration : 19, loss : 1.3724557161331177\n",
      "iteration : 20, loss : 1.3634209632873535\n",
      "iteration : 21, loss : 1.3564224243164062\n",
      "iteration : 22, loss : 1.351001501083374\n",
      "iteration : 23, loss : 1.3468025922775269\n",
      "iteration : 24, loss : 1.3435497283935547\n",
      "iteration : 25, loss : 1.3410301208496094\n",
      "iteration : 26, loss : 1.3390783071517944\n",
      "iteration : 27, loss : 1.3375662565231323\n",
      "iteration : 28, loss : 1.3363949060440063\n",
      "iteration : 29, loss : 1.3354873657226562\n",
      "iteration : 30, loss : 1.3347841501235962\n",
      "iteration : 31, loss : 1.3342393636703491\n",
      "iteration : 32, loss : 1.3338171243667603\n",
      "iteration : 33, loss : 1.3334898948669434\n",
      "iteration : 34, loss : 1.3332362174987793\n",
      "iteration : 35, loss : 1.3330392837524414\n",
      "iteration : 36, loss : 1.3328866958618164\n",
      "iteration : 37, loss : 1.332768440246582\n",
      "iteration : 38, loss : 1.3326765298843384\n",
      "iteration : 39, loss : 1.3326048851013184\n",
      "iteration : 40, loss : 1.3325493335723877\n",
      "iteration : 41, loss : 1.3325062990188599\n",
      "iteration : 42, loss : 1.3324722051620483\n",
      "iteration : 43, loss : 1.332445740699768\n",
      "iteration : 44, loss : 1.3324252367019653\n",
      "iteration : 45, loss : 1.3324090242385864\n",
      "iteration : 46, loss : 1.3323962688446045\n",
      "iteration : 47, loss : 1.3323860168457031\n",
      "iteration : 48, loss : 1.3323777914047241\n",
      "iteration : 49, loss : 1.3323711156845093\n"
     ]
    }
   ],
   "source": [
    "EPS = 1e-2\n",
    "EPOCHS=50\n",
    "\n",
    "#Réseau à la main (on le refera à la main derriere)\n",
    "class DeuxCouches(torch.nn.Module):\n",
    "  def __init__(self, Xdim):\n",
    "    super(DeuxCouches,self).__init__()\n",
    "    self.un = torch.nn.Linear(Xdim,5)\n",
    "    self.act = torch.nn.Tanh()\n",
    "    self.deux = torch.nn.Linear(5,1)\n",
    "  def forward(self,x):\n",
    "    return self.deux(self.act(self.un(x)))\n",
    "\n",
    "netDeuxCouches = DeuxCouches(Xdim)\n",
    "\n",
    "mseloss = torch.nn.MSELoss()\n",
    "    \n",
    "optim = torch.optim.SGD(params=netDeuxCouches.parameters(),lr=EPS)\n",
    "for i in range(EPOCHS):\n",
    "    loss = mseloss(netDeuxCouches(housing_x),housing_y.view(-1,1))\n",
    "    print(f\"iteration : {i}, loss : {loss}\")\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration : 0, loss : 4.2730913162231445\n",
      "iteration : 1, loss : 3.654235601425171\n",
      "iteration : 2, loss : 3.166243076324463\n",
      "iteration : 3, loss : 2.78090500831604\n",
      "iteration : 4, loss : 2.4770936965942383\n",
      "iteration : 5, loss : 2.238438606262207\n",
      "iteration : 6, loss : 2.051255226135254\n",
      "iteration : 7, loss : 1.904779314994812\n",
      "iteration : 8, loss : 1.7901215553283691\n",
      "iteration : 9, loss : 1.7003779411315918\n",
      "iteration : 10, loss : 1.6301881074905396\n",
      "iteration : 11, loss : 1.57527494430542\n",
      "iteration : 12, loss : 1.5322285890579224\n",
      "iteration : 13, loss : 1.4984314441680908\n",
      "iteration : 14, loss : 1.4718306064605713\n",
      "iteration : 15, loss : 1.4508253335952759\n",
      "iteration : 16, loss : 1.4342093467712402\n",
      "iteration : 17, loss : 1.4210708141326904\n",
      "iteration : 18, loss : 1.4106755256652832\n",
      "iteration : 19, loss : 1.4024348258972168\n",
      "iteration : 20, loss : 1.3959072828292847\n",
      "iteration : 21, loss : 1.3907508850097656\n",
      "iteration : 22, loss : 1.3866708278656006\n",
      "iteration : 23, loss : 1.383420467376709\n",
      "iteration : 24, loss : 1.3807920217514038\n",
      "iteration : 25, loss : 1.3786122798919678\n",
      "iteration : 26, loss : 1.376739501953125\n",
      "iteration : 27, loss : 1.375065803527832\n",
      "iteration : 28, loss : 1.3735288381576538\n",
      "iteration : 29, loss : 1.3721522092819214\n",
      "iteration : 30, loss : 1.3710336685180664\n",
      "iteration : 31, loss : 1.3701608180999756\n",
      "iteration : 32, loss : 1.3694435358047485\n",
      "iteration : 33, loss : 1.3688275814056396\n",
      "iteration : 34, loss : 1.3682857751846313\n",
      "iteration : 35, loss : 1.3678040504455566\n",
      "iteration : 36, loss : 1.367374300956726\n",
      "iteration : 37, loss : 1.366990327835083\n",
      "iteration : 38, loss : 1.366645336151123\n",
      "iteration : 39, loss : 1.366331696510315\n",
      "iteration : 40, loss : 1.3660423755645752\n",
      "iteration : 41, loss : 1.3657710552215576\n",
      "iteration : 42, loss : 1.3655126094818115\n",
      "iteration : 43, loss : 1.3652626276016235\n",
      "iteration : 44, loss : 1.3650180101394653\n",
      "iteration : 45, loss : 1.3647749423980713\n",
      "iteration : 46, loss : 1.3645302057266235\n",
      "iteration : 47, loss : 1.3642795085906982\n",
      "iteration : 48, loss : 1.364018201828003\n",
      "iteration : 49, loss : 1.3637418746948242\n"
     ]
    }
   ],
   "source": [
    "#Création d'un réseau à 1 couche cachée avec le module séquentiel (remplace l'objet précédent)\n",
    "netSeq = torch.nn.Sequential(torch.nn.Linear(Xdim,5),torch.nn.Tanh(),torch.nn.Linear(5,1))\n",
    "mseloss = torch.nn.MSELoss()    \n",
    "optim = torch.optim.SGD(params=netSeq.parameters(),lr=EPS) # extraction auto des paramètres :)\n",
    "for i in range(EPOCHS):\n",
    "    loss = mseloss(netSeq(housing_x),housing_y.view(-1,1))\n",
    "    print(f\"iteration : {i}, loss : {loss}\")\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJ4MoJP4k4i0"
   },
   "source": [
    "## B. Outils annexes\n",
    "\n",
    "### B.0 tdqm\n",
    "Afin de rendre les boucles `for` plus élégantes et surtout plus *suivable*, il faut utiliser le package `tdqm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# avant tdqm\n",
    "import time\n",
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    time.sleep(np.random.rand())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:51<00:00,  1.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# après, avec tdqm\n",
    "from tqdm import tqdm \n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    # print(i)\n",
    "    time.sleep(np.random.rand())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### B.1. DataLoader\n",
    "\n",
    "Pytorch dispose d'un ensemble d'outils qui permettent de simplifier les démarches expérimentales. Nous allons voir en particulier en commençant par\n",
    "* le DataLoader qui permet de gérer le chargement de données, le partitionement et la constitution d'ensembles de test et d'apprentissage; \n",
    "\n",
    "Le <a href=https://pytorch.org/docs/stable/data.html>**DataLoader**</a> et la classe associée <a href=https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset> **Dataset**</a>  permettent en particulier de :\n",
    "* charger des données\n",
    "* pré-processer les données\n",
    "* de gérer les mini-batchs (sous-ensembles sur lequel on effectue une descente de gradient).\n",
    "\n",
    "La classe **Dataset** est une classe abstraite qui nécessite l'implémentation que d'une seule méthode, ```__getitem__(self,index)``` : elle renvoie le i-ème objet du jeu de données (généralement un couple *(exemple,label)*. \n",
    "\n",
    "La classe **TensorDataset** est l'instanciation la plus courante d'un **Dataset**, elle permet de créer un objet **Dataset** à partir d'une liste de tenseurs qui renvoie pour un index $i$ donné le tuple contenant les $i$-èmes ligne de chaque tenseur.\n",
    "\n",
    "La classe **DataLoader** permet essentiellement de randomiser et de constituer des mini-batchs de façon simple à partir d'une instance de **Dataset**. Chaque mini-batch est constitué d'exemples tirés aléatoirement dans le **Dataset** passé en paramètre et mis bout à bout dans des tenseurs. La méthode ```collate_fn(*args)``` est utilisée pour cela (nous verrons une customization de cette fonction dans une séance ultérieure). C'est ce générateur qui est généralement parcouru lors de l'apprentissage à chaque itération d'optimisation.\n",
    "\n",
    "Voici un exemple de code pour utiliser le DataLoader : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "AZaWAFO8k8ze"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET:\n",
      " 20640 (tensor([   4.0368,   52.0000,    4.7617,    1.1036,  413.0000,    2.1399,\n",
      "          37.8500, -122.2500]), tensor(2.6970))\n",
      "DATA LOADER:\n",
      " 1290 \n",
      " torch.Size([16, 8])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "\n",
    "## Création d'un dataset à partir des deux tenseurs d'exemples et de labels\n",
    "train_data = TensorDataset(housing_x,housing_y)\n",
    "## On peut indexer et connaitre la longueur d'un dataset\n",
    "print(\"DATASET:\\n\",len(train_data),train_data[5])\n",
    "\n",
    "## Création d'un DataLoader\n",
    "## tailles de mini-batch de 16, shuffle=True permet de mélanger les exemples\n",
    "# loader est un itérateur sur les mini-batchs des données\n",
    "loader = DataLoader(train_data, batch_size=16,shuffle=True ) # n'hésitez pas à jouer avec les paramètres\n",
    "\n",
    "#Premier batch (aléatoire) du dataloader : (nb batch = len/batch_size)\n",
    "print(\"DATA LOADER:\\n\",len(iter(loader)),\"\\n\",next(iter(loader))[0].size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpréter les dimensions issues du data loader pour être sur que le processus est compris en profondeur\n",
    "\n",
    "* Combien de fois chaque point est-il vu?\n",
    "* En combien de calcul traite-t-on l'ensemble des données?\n",
    "* Ecrire au brouillon l'expression littérale développée de `cumloss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss : 1.3320: 100%|██████████| 50/50 [00:28<00:00,  1.74it/s]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=50\n",
    "EPS=1e-4\n",
    "netSeq = torch.nn.Sequential(torch.nn.Linear(Xdim,5),torch.nn.Tanh(),torch.nn.Linear(5,1))\n",
    "optim = torch.optim.SGD(params=netSeq.parameters(),lr=EPS)\n",
    "\n",
    "# La boucle d'apprentissage :\n",
    "loop = tqdm(range(EPOCHS))\n",
    "for i in loop:\n",
    "    cumloss = 0\n",
    "    # On parcourt tous les exemples par batch de 16 (paramètre batch_size de DataLoader)\n",
    "    for bx,by in loader:\n",
    "        loss = mseloss(netSeq(bx).view(-1),by)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        cumloss += loss.item() # item pour un scalaire (sinon .data ou detach)\n",
    "    # old way\n",
    "    # print(f\"iteration : {i}, loss : {cumloss/len(loader)}\") # loss sur un batch => diviser pour avoir une grandeur interprétable\n",
    "    # new way with tqdm => On ajoute le message dans la barre de progression\n",
    "    loop.set_description(f\"loss : {cumloss/len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9x2LC_6lCQm"
   },
   "source": [
    "### B.2 Checkpointing\n",
    "Les modèles Deep sont généralement long à apprendre. Afin de ne pas perdre des résultats en cours de calcul, il est fortement recommander de faire du **checkpointing**, c'est-à-dire d'enregistrer des points d'étapes du modèle en cours d'apprentissage pour pouvoir reprendre à n'importe quel moment l'apprentissage du modèle en cas de problème.  Il s'agit en pratique de sauvegarder l'état du modèle et de l'optimisateur (et de tout autre objet qui peut servir lors de l'apprentissage) toutes les n itérations. Toutes les variables d'intérêt sont en général disponibles par la méthode **state_dict()** des modèles et de l'optimiseur. \n",
    "\n",
    "En pratique, vous pouvez utilisé un code dérivé de celui ci-dessous.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "URQTq8hrPJO0"
   },
   "outputs": [],
   "source": [
    "# Il existe différentes solutions: en voici une\n",
    "# mais ça marche\n",
    "# \n",
    "import os\n",
    "\n",
    "def save_state(epoch,model,optim,fichier):\n",
    "      \"\"\" sauvegarde du modèle et de l'état de l'optimiseur dans fichier \"\"\"\n",
    "      state = {'epoch' : epoch, 'model_state': model.state_dict(), 'optim_state': optim.state_dict()}\n",
    "      torch.save(state,fichier) # pas besoin de passer par pickle\n",
    " \n",
    "def load_state(fichier,model,optim):\n",
    "      \"\"\" Si le fichier existe, on charge le modèle et l'optimiseur \"\"\"\n",
    "      epoch = 0\n",
    "      if os.path.isfile(fichier):\n",
    "          state = torch.load(fichier)\n",
    "          model.load_state_dict(state['model_state'])\n",
    "          optim.load_state_dict(state['optim_state'])\n",
    "          epoch = state['epoch']\n",
    "\n",
    "      return epoch\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exécuter 2 fois les boites ci-dessous:\n",
    "* Première itération = 50 epochs\n",
    "* Deuxième itéation... Anticiper le nombre d'époch !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "# construction rapide d'un réseau de neurones de type PMC\n",
    "netSeq = torch.nn.Sequential(torch.nn.Linear(Xdim,5),torch.nn.Tanh(),torch.nn.Linear(5,1))\n",
    "optim = torch.optim.SGD(params=netSeq.parameters(),lr=EPS) # extraction auto des paramètres\n",
    "\n",
    "fichier = \"/tmp/netSeq.pth\"\n",
    "start_epoch = load_state(fichier,netSeq,optim)\n",
    "print(start_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:48<00:00,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in tqdm(range(start_epoch,EPOCHS)):\n",
    "    cumloss = 0\n",
    "    for bx,by in loader:\n",
    "        loss = mseloss(netSeq(bx).view(-1),by)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        cumloss += loss.item()\n",
    "    if epoch % 10 ==0: save_state(epoch,netSeq,optim,fichier)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IstQCvKblSvT"
   },
   "source": [
    "\n",
    "### B.3 GPU \n",
    "Afin d'utiliser un GPU lors des calculs, il est nécessaire de transférer les données et le modèle sur le GPU par l'intermédiaire de la fonction **to(device)** des tenseurs et des modules.  Il est impossible de faire une opération lorsqu'une partie des tenseurs sont sur GPU et l'autre sur CPU. Il faut que tous les tenseurs et paramètres soient sur le même device ! On doit donc s'assurer que le modèle, les exemples et les labels sont sur GPU pour faire les opérations.\n",
    "\n",
    "Par ailleurs, on peut connaître le device sur lequel est chargé un tenseur par l'intermédiaire de ```.device``` (mais pas pour un modèle, il faut aller voir les paramètres dans ce cas).\n",
    "\n",
    "Une manière simple d'utiliser un GPU quand il existe et donc d'avoir un code agnostique est la suivante : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Fs8s7EwwlWTn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch  0\n",
      "batch  10\n",
      "batch  20\n",
      "batch  30\n",
      "batch  40\n",
      "batch  50\n",
      "batch  60\n",
      "batch  70\n",
      "batch  80\n",
      "batch  90\n",
      "batch  100\n",
      "batch  110\n",
      "batch  120\n",
      "batch  130\n",
      "batch  140\n",
      "batch  150\n",
      "batch  160\n",
      "batch  170\n",
      "batch  180\n",
      "batch  190\n",
      "batch  200\n",
      "batch  210\n",
      "batch  220\n",
      "batch  230\n",
      "batch  240\n",
      "batch  250\n",
      "batch  260\n",
      "batch  270\n",
      "batch  280\n",
      "batch  290\n",
      "batch  300\n",
      "batch  310\n",
      "batch  320\n",
      "batch  330\n",
      "batch  340\n",
      "batch  350\n",
      "batch  360\n",
      "batch  370\n",
      "batch  380\n",
      "batch  390\n",
      "batch  400\n",
      "batch  410\n",
      "batch  420\n",
      "batch  430\n",
      "batch  440\n",
      "batch  450\n",
      "batch  460\n",
      "batch  470\n",
      "batch  480\n",
      "batch  490\n",
      "batch  500\n",
      "batch  510\n",
      "batch  520\n",
      "batch  530\n",
      "batch  540\n",
      "batch  550\n",
      "batch  560\n",
      "batch  570\n",
      "batch  580\n",
      "batch  590\n",
      "batch  600\n",
      "batch  610\n",
      "batch  620\n",
      "batch  630\n",
      "batch  640\n",
      "batch  650\n",
      "batch  660\n",
      "batch  670\n",
      "batch  680\n",
      "batch  690\n",
      "batch  700\n",
      "batch  710\n",
      "batch  720\n",
      "batch  730\n",
      "batch  740\n",
      "batch  750\n",
      "batch  760\n",
      "batch  770\n",
      "batch  780\n",
      "batch  790\n",
      "batch  800\n",
      "batch  810\n",
      "batch  820\n",
      "batch  830\n",
      "batch  840\n",
      "batch  850\n",
      "batch  860\n",
      "batch  870\n",
      "batch  880\n",
      "batch  890\n",
      "batch  900\n",
      "batch  910\n",
      "batch  920\n",
      "batch  930\n",
      "batch  940\n",
      "batch  950\n",
      "batch  960\n",
      "batch  970\n",
      "batch  980\n",
      "batch  990\n",
      "batch  1000\n",
      "batch  1010\n",
      "batch  1020\n",
      "batch  1030\n",
      "batch  1040\n",
      "batch  1050\n",
      "batch  1060\n",
      "batch  1070\n",
      "batch  1080\n",
      "batch  1090\n",
      "batch  1100\n",
      "batch  1110\n",
      "batch  1120\n",
      "batch  1130\n",
      "batch  1140\n",
      "batch  1150\n",
      "batch  1160\n",
      "batch  1170\n",
      "batch  1180\n",
      "batch  1190\n",
      "batch  1200\n",
      "batch  1210\n",
      "batch  1220\n",
      "batch  1230\n",
      "batch  1240\n",
      "batch  1250\n",
      "batch  1260\n",
      "batch  1270\n",
      "batch  1280\n",
      "Device du mini-batch :  cpu\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "# poru les possesseur de mac MXX:\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "## On charge le modèle sur GPU\n",
    "## A faire avant la déclaration de l'optimiseur, sinon les paramètres optimisés ne seront pas les mêmes! \n",
    "## model =  model.to(device) \n",
    "loader = DataLoader(TensorDataset(housing_x,housing_y), batch_size=16,shuffle=True ) \n",
    "\n",
    "netSeq = torch.nn.Sequential(torch.nn.Linear(Xdim,5),torch.nn.Tanh(),torch.nn.Linear(5,1))\n",
    "netSeq = netSeq.to(device)\n",
    "optim = torch.optim.SGD(params=netSeq.parameters(),lr=EPS)\n",
    "\n",
    "for i,(bx,by) in enumerate(loader):\n",
    "    ## On charge le batch sur GPU\n",
    "    bx, by = bx.to(device), by.to(device)\n",
    "    loss = mseloss(netSeq(bx).view(-1),by)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if i % 10 ==0: print(\"batch \",i)\n",
    "\n",
    "\n",
    "print(\"Device du mini-batch : \", bx.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5J1b55_lFR-"
   },
   "source": [
    "\n",
    "### B.4 TensorBoard\n",
    "\n",
    "Durant l'apprentissage de vos modèles, il est agréable de visualiser de quelle manière évolue le coût, la précision sur l'ensemble de validation ainsi que d'autres éléments. TensorFlow dispose d'un outil très apprécié, le TensorBoard, qui permet de gérer très facilement de tels affichages. On retrouve tensorboard dans **Pytorch** dans ```torch.utils.tensorboard``` qui permet de faire le pont de pytorch vers cet outil. \n",
    "\n",
    "Le principe est le suivant :\n",
    "* tensorboard fait tourner en fait un serveur web local qui va lire les fichiers de log dans un répertoire local. L'affichage se fait dans votre navigateur à partir d'un lien fourni lors du lancement de tensorboard.\n",
    "* Les éléments que vous souhaitez visualiser (scalaire, graphes, distributions, histogrammes) sont écrits dans le fichier de log à partir d'un objet **SummaryWriter** .\n",
    "* la méthode ```add_scalar(tag, valeur, global_step)``` permet de logger une valeur à un step donné, ```add_scalar(tag, tag_scalar_dic, global_step)``` un ensemble de valeurs par l'intermédiaire du dictionnaire ```tag_scalar_dic``` (un regroupement des scalaires est fait en fonction du tag passé, chaque sous-tag séparé par un **/**).\n",
    "\n",
    "Il existe d'autres méthodes ```add_XXX``` pour visualiser par exemple des images, des histogrammes (cf <a href=https://pytorch.org/docs/stable/tensorboard.html>la doc </a>).\n",
    "\n",
    "Le code suivant illustre une manière de l'utiliser. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Informations</h2><div>Pour visualiser les logs, tapez la commande : </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard --logdir c:\\tmp\\logs\n",
      "Une fois effectué, copier-coller l'URL dans votre navigateur pour avoir les courbes d'apprentissage\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION 1: lancer tensorboard, ecrire des loss (ou autres indicateurs) dans un fichiers + lancer la visu dans dans un navigateur à part\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "\n",
    "# outils avancés de gestion des chemins\n",
    "BASEPATH = Path(\"/tmp\")\n",
    "TB_PATH =  BASEPATH / \"logs\"\n",
    "TB_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# usage externe de tensorboard: (1) lancer la commande dans une console; (2) copier-coller l'URL dans un navigateur\n",
    "display(HTML(\"<h2>Informations</h2><div>Pour visualiser les logs, tapez la commande : </div>\"))\n",
    "print(f\"tensorboard --logdir {Path(TB_PATH).absolute()}\")\n",
    "print(\"Une fois effectué, copier-coller l'URL dans votre navigateur pour avoir les courbes d'apprentissage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1kIhHDnElQd8"
   },
   "outputs": [],
   "source": [
    "# SOLUTION 2: Tensorbord à l'interieur du notebook (simple mais pas le plus pratique)\n",
    "\n",
    "# Solution moins intéressante: ne décommenter qu'en cas d'échec de la première solution !!\n",
    "\n",
    "# # Spécial notebook, les commandes suivantes permettent de lancer tensorboard\n",
    "# # En dehors du notebook, il faut le lancer à la main dans le shell : \n",
    "# # tensorboard --logdir logs\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir /tmp/logs\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# # Spécial notebook : pour avoir les courbes qui s'affichent dans le notebook, \n",
    "# # sinon aller à l'adresse web local indiquée lors du lancement de tensorboard\n",
    "# from tensorboard import notebook\n",
    "# notebook.display() # A voir si vous avez une autre fenêtre de gestion de tensorboard ou si vous le voulez à la suite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:15<00:00,  7.56s/it]\n",
      "100%|██████████| 10/10 [02:16<00:00, 13.65s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EPS = 1e-5\n",
    "EPOCHS=10\n",
    "netSeq = torch.nn.Sequential(torch.nn.Linear(Xdim,5),torch.nn.Tanh(),torch.nn.Linear(5,1))\n",
    "netDeuxCouches = DeuxCouches(Xdim)\n",
    "netSeq.name = \"Sequentiel\" # nommer les modèles\n",
    "netDeuxCouches.name = \"DeuxCouches\"\n",
    "\n",
    "mseloss = torch.nn.MSELoss()\n",
    "for model in [netSeq, netDeuxCouches]:\n",
    "    ## Obtention d'un SummaryWriter\n",
    "    ## meme répertoire que la commande %tensorboard --logdir logs \n",
    "    summary = SummaryWriter(f\"/tmp/logs/test/{model.name}/\") # on peut ajouter un timestamp ou des paramètres\n",
    "\n",
    "    optim = torch.optim.SGD(params=model.parameters(),lr=EPS) \n",
    "    for i in tqdm(range(EPOCHS)):\n",
    "        cumloss = 0\n",
    "        for bx, by in loader:\n",
    "            loss = mseloss(model(housing_x),housing_y.view(-1,1))\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()  \n",
    "            cumloss+= loss.item()\n",
    "        summary.add_scalar(f\"loss\",cumloss,i) # c'est ici qu'on fait le lien\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction du sujet à partir de la correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  TODO )\",\" TODO \",\\\n",
    "    txt, flags=re.DOTALL))\n",
    "f2.close()\n",
    "\n",
    "### </CORRECTION> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DeepLearning fc TP1 2020-2021-correction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
