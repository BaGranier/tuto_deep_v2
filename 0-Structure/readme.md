# Prise en main de `pytorch`

Note: les tutoriels *officiels* sont de très grande qualité et méritent toute votre attention si vous voulez approfondir certains points. La plupart des notebooks proposés sont dérivés de ces propositions et des travaux de Nicolas Baskiotis et Benjamin Piwowarski à Sorbonne Université. [lien](https://docs.pytorch.org/tutorials/index.html)


### Notebook 0: types des données, opérateurs en pytorch

**Vous n'en avez normalement pas besoin après les cours sur `numpy`/`scikit-learn`** : les opérateurs sont les mêmes. Passez directement au notebook 1.

### Notebook 1: vers le gradient dans les tenseurs

Encore des opérateurs, juste pour vérifier que tout est bien OK (on passera très vite après les TP `numpy`/`scikit-learn`)

Le notebook à travailler est le suivant: introduction sur le gradient et son fonctionnement. Si vous voulez plus de détails, n'hésitez pas à retourner [ici](https://github.com/vguigue/tuto_numpy/tree/main/4_gradient).

- tensor, gradient
- vers la régression linéaire:
    - fonction de coût
    - algorithme itératif d'optimisation
